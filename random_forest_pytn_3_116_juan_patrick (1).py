# -*- coding: utf-8 -*-
"""Random Forest PYTN_3_116_Juan Patrick

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xOLTcdl3sNJF2wyNRXlzJN-MBXfs_Vk9

Import library
"""

import pandas as pd
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

"""Load dataset

link: https://archive.ics.uci.edu/dataset/222/bank+marketing
*italicized text*
"""

df = pd.read_csv('/content/drive/MyDrive/HACKTIV8/Tugas 3/bank-additional-full.csv', sep=';')
df.head()

"""pisahkan fitur dan target:

- X = df.frop('y', axis=1) --> fitur (semua kolom kecuali target)
- y = df['y']  --> target kolom 'y'

fungsi:
- x berisi semua informasi klien (umur, pekerjaan, marital, dll.)
- y adalah label target: apakah klien men-subscribe deposito (yes/no)
"""

X = df.drop('y', axis=1)
y = df['y']

"""Preprocessing untuk ubah kolom kategorikal menjadi numerik dan mengubah 'yes' menjadi 1 dan 'no' menjadi 0

- get_dummies(): mengubah kolom teks (job, marital, dll) menjadi angka biner
- LabelEncoder: mengubah kolom target dari string ("yes", "no") ke angka (1, 0)
"""

X_encoded = pd.get_dummies(X)
le = LabelEncoder()
y_encoded = le.fit_transform(y)   # yes = 1, no = 0

"""Split dataset training dan testing:
- membagi dataset menjadi:
75% untuk training dan 25% untuk testing
"""

# split data train and test
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.25, random_state=42)

"""Melatih Model Random Forest:
- n_estimators=100  --> 100 pohon keputusan
- max_depth=10 --> kedalaman maksimum level 10 untuk mencegah overfitting
"""

# Buat dan latih model Random Forest
rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
rf.fit(X_train, y_train)

"""Melakukan prediksi dan evaluasi akurasi dan laporan:
- Menggunakan model yang sudah dilatih untuk memprediksi apakah klien y=yes atau no pada uji X_test

Evaluasi akurasi dan laporan:
- accuracy_score: presentase prediksi yang benar
- classification_report: precision, recall, f1-score
- confusion_matrix: menghitung prediksi benar dan salah untuk tiap kelas

Penjelasan terkait hasil:
- 9013: prediksi benar untuk tidak langganan
- 131: prediksi benar untuk langganan
- 807: salah prediksi (harusnya yes, dikira no)
- 346: salah prediksi (harusnya no, dikira yes
"""

y_pred = rf.predict(X_test)

print("Akurasi: ", accuracy_score(y_test, y_pred))
print("\nClassification report: \n", classification_report(y_test, y_pred))
print("\nConfusion Matrix :\n", confusion_matrix(y_test, y_pred))

"""Visualisasi COnfusion Matrix:
- menampilkan confusion matrix dalam bentuk heatmap agar mudah dibaca
- annot=True: tampilkan angka dalam kotak
- xticklabels dan yticklabels: label kelas yang mudah dimengerti
"""

# confusion matrix

# menggunakan hasil prediksi dari model yang saya buat
cm = confusion_matrix(y_test, y_pred)
labels = ['No', 'Yes']

plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - Random Forest')
plt.tight_layout()
plt.show()

"""Algoritma yang digunakan: Random Forest

Alasannya:
- Akurat
- cepat
- stabil
- bisa tangani kategorikal/numerik

Berikut adalah perbandingannya dengan algoritma lain:

1. Logistic regression: tidak cukup kuat untuk menangani hubungan non-linear dan data kompleks

2. KNN: Lemot untuk data besar, perlu standarisasi, sensitif ke skala fitur dan noise

3. SVM: boros memori di data besar, perlu preprocessing intensif

4. Neural Network (ANN): butuh banyak tuning, lambat, dan kurang interpretatif

5. Naive bayes (NB): Tidak cocok untuk data marketing yang kompleks

6. XGBoost: training sedikit lebih lambat dan setup lebih kompleks daripada Random Forest

7. LightGBM: perlu install tambahan dan kurang interpretatif serta lebih kompleks jika dibanding dengan Random Forest

"""